{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM using Representatives",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS5Y223kAhkq"
      },
      "source": [
        "Load Libararies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28vFh3x9zG7u",
        "outputId": "83836f9e-c3d0-4c3e-ff38-bb10323b3fe1"
      },
      "source": [
        "!pip install hdf5storage\n",
        "from __future__ import division\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from matplotlib import image\n",
        "from sklearn import svm\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import numpy.matlib\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "import numpy.matlib\n",
        "import sys\n",
        "import hdf5storage\n",
        "import scipy.io\n",
        "import time\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hdf5storage\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/c2/754164946f40afc64421777340fb2372c0483e4c68a7ac5cffde85beaf1d/hdf5storage-0.1.17-py2.py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 40kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.1; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (2.10.0)\n",
            "Requirement already satisfied: numpy; python_version >= \"3.4\" in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1; python_version >= \"3.3\"->hdf5storage) (1.15.0)\n",
            "Installing collected packages: hdf5storage\n",
            "Successfully installed hdf5storage-0.1.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7qg5DnMBDPC"
      },
      "source": [
        "Loading representative dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ukhQXSC_e-o",
        "outputId": "c5a690c3-c19b-4f3f-ff99-33d3746d88b4"
      },
      "source": [
        "trainX=[]\n",
        "trainY=[]\n",
        "\n",
        "classes = ['Buildings', 'Forests', 'Glacier', 'Mountain', 'sea', 'street']\n",
        "\n",
        "for ind,cls in enumerate(classes):\n",
        "  print(cls)\n",
        "  image_folder_train = Path('/content/drive/MyDrive/Representatives/' + cls + '/').rglob('*.jpg')\n",
        "  files = [x for x in image_folder_train]\n",
        "  for f in files: \n",
        "    \n",
        "    image = Image.open(f)\n",
        "    image = np.asarray(image)\n",
        "    if image.shape == (150, 150, 3):\n",
        "      trainX.append(image)\n",
        "      trainY.append(ind)\n",
        "\n",
        "\n",
        "trainX=np.array(trainX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Buildings\n",
            "Forests\n",
            "Glacier\n",
            "Mountain\n",
            "sea\n",
            "street\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6z1VG-QBJkw"
      },
      "source": [
        "Dimensionality reduction using Principle Component Analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P2vimTxL0RI"
      },
      "source": [
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "trainY=np.array(trainY)\n",
        "trainX1 = trainX.flatten().reshape(trainX.shape[0], 150*150*3) \n",
        "trainX11 = StandardScaler().fit_transform(trainX1)\n",
        "pca = PCA(n_components=100)\n",
        "trainX111 = pca.fit_transform(trainX11)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH_2rX9B3nt0",
        "outputId": "5f341c94-dc6c-41de-99b6-215c5de4a7ca"
      },
      "source": [
        "Comp=pca.components_.T\n",
        "print(Comp.shape)\n",
        "print(trainX111.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(67500, 100)\n",
            "(3063, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfT2H2meBaBO"
      },
      "source": [
        "New trained data with after PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "068ZgBiyyhw_"
      },
      "source": [
        "Train= np.c_[trainX111,trainY]\n",
        "\n",
        "np.random.shuffle(Train)\n",
        "\n",
        "trainX11=Train[:,:-1]\n",
        "trainY1=Train[:,-1]\n",
        "\n",
        "\n",
        "print(trainY1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwZUROziBtIc"
      },
      "source": [
        "Loading Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSuX_uUw2oJk",
        "outputId": "9faafb3f-1c81-49ae-a28a-cec086a23f55"
      },
      "source": [
        "testX=[]\n",
        "testY=[]\n",
        "\n",
        "classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
        "\n",
        "for ind,cls in enumerate(classes):\n",
        "  \n",
        "  image_folder_test = Path('/content/drive/MyDrive/ImageClassificationProject/seg_test/seg_test/' + cls + '/').rglob('*.jpg')\n",
        "  files = [x for x in image_folder_test]\n",
        "  for f in files: \n",
        " \n",
        "    image = Image.open(f)\n",
        "    image = np.asarray(image)\n",
        "    if image.shape == (150, 150, 3):\n",
        "      testX.append(image)\n",
        "      testY.append(ind)\n",
        "\n",
        "\n",
        "testX=np.array(testX)\n",
        "\n",
        "print(testX.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3003, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uraBBp9HBznU"
      },
      "source": [
        "Project the test data on the new features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVDZXkYGJxqZ"
      },
      "source": [
        "testX1 = testX.flatten().reshape(testX.shape[0], 150*150*3) \n",
        "testX2=np.matmul(testX1, Comp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VQT6ElsB6Q9"
      },
      "source": [
        "Training an Training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTuIKkwBg9p1",
        "outputId": "ef1a5f75-9297-430f-c6f6-bce0fea3dcbc"
      },
      "source": [
        "csf = svm.SVC(C=10000,kernel='poly',decision_function_shape='ovr',gamma=0.01,degree=4 )\n",
        "csf.fit(trainX11, trainY1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=10000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=4, gamma=0.01, kernel='poly',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DOfdKwMCCHa"
      },
      "source": [
        "Testing the classifer on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj7PezNtaz5V",
        "outputId": "008af95e-003e-43d8-c4aa-b4ba11b953ec"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "yp=csf.predict(testX2)\n",
        "accuracy_score(testY, yp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.19080919080919082"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAZOO5bi5QeV"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(testY, yp)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm)\n",
        "\n",
        "# We want to show all ticks...\n",
        "ax.set_xticks(np.arange(len(classes)))\n",
        "ax.set_yticks(np.arange(len(classes)))\n",
        "# ... and label them with the respective list entries\n",
        "ax.set_xticklabels(classes)\n",
        "ax.set_yticklabels(classes)\n",
        "\n",
        "ax.set_ylabel(\"True Labels\")\n",
        "ax.set_xlabel(\"Predicted Labels\")\n",
        "for i in range(len(classes)):\n",
        "    for j in range(len(classes)):\n",
        "        text = ax.text(j, i, cm[i, j],\n",
        "                       ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "ax.set_title(\"Confusion Matrix\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}